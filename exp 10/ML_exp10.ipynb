{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObMwP65G0Ur5hVncfMfXFm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chandni0369/ML-LAB-D11ADA-57/blob/main/exp%2010/ML_exp10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1c03wwkJXJx",
        "outputId": "f07281cc-ec3d-4f26-bbfb-c3244c80e7ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter number of inputs: 3\n",
            "\n",
            "All possible input combinations:\n",
            "[[0 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [1 1 0]\n",
            " [1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "n = int(input(\"Enter number of inputs: \"))\n",
        "X = np.array([list(map(int, np.binary_repr(i, n))) for i in range(2**n)])\n",
        "print(\"\\nAll possible input combinations:\")\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array([1 if np.all(x == 1) else -1 for x in X])\n",
        "print(\"\\nTarget Output (for AND Gate):\")\n",
        "print(y)\n",
        "\n",
        "weights = np.zeros(n)\n",
        "bias = 0\n",
        "lr = 1  #learning rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJZnPMLaJqAO",
        "outputId": "172b30ca-60a0-4df7-f87f-9b0c6939aa5b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target Output (for AND Gate):\n",
            "[-1 -1 -1 -1 -1 -1 -1  1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "records = []\n",
        "\n",
        "for i in range(len(X)):\n",
        "    x = np.where(X[i] == 0, -1, 1)   # convert 0â†’-1 for bipolar input\n",
        "    weights += lr * x * y[i]\n",
        "    bias += lr * y[i]\n",
        "    records.append([i+1, *weights, bias])\n",
        "\n",
        "cols = ['Sample', *[f'W{i+1}' for i in range(n)], 'Bias']\n",
        "df_weights = pd.DataFrame(records, columns=cols)\n",
        "\n",
        "print(\"\\nHebbian Learning Weight Update Table:\\n\")\n",
        "print(df_weights.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7S5sdD5Jy4T",
        "outputId": "bf91b622-7067-4eb7-fa1b-b854c3212599"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hebbian Learning Weight Update Table:\n",
            "\n",
            " Sample  W1  W2  W3  Bias\n",
            "      1 3.0 3.0 3.0    -7\n",
            "      2 4.0 4.0 2.0    -8\n",
            "      3 5.0 3.0 3.0    -9\n",
            "      4 6.0 2.0 2.0   -10\n",
            "      5 5.0 3.0 3.0   -11\n",
            "      6 4.0 4.0 2.0   -12\n",
            "      7 3.0 3.0 3.0   -13\n",
            "      8 4.0 4.0 4.0   -12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFinal learned weights and bias:\")\n",
        "print(\"Weights:\", weights)\n",
        "print(\"Bias:\", bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNzMMbOnKe1F",
        "outputId": "216b0683-fd6c-4faa-8298-abf52cfdafaa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final learned weights and bias:\n",
            "Weights: [4. 4. 4.]\n",
            "Bias: -12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTesting the learned Hebbian model:\\n\")\n",
        "\n",
        "for i in range(len(X)):\n",
        "    x = np.where(X[i] == 0, -1, 1)\n",
        "    net = np.dot(x, weights) + bias\n",
        "    output = 1 if net > 0 else -1\n",
        "    print(f\"Input: {x}  |  Net: {net:.2f}  |  Output: {output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fAzojB4KrQv",
        "outputId": "67c54f38-a63f-496e-a7f2-395891b5c60d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing the learned Hebbian model:\n",
            "\n",
            "Input: [-1 -1 -1]  |  Net: -24.00  |  Output: -1\n",
            "Input: [-1 -1  1]  |  Net: -16.00  |  Output: -1\n",
            "Input: [-1  1 -1]  |  Net: -16.00  |  Output: -1\n",
            "Input: [-1  1  1]  |  Net: -8.00  |  Output: -1\n",
            "Input: [ 1 -1 -1]  |  Net: -16.00  |  Output: -1\n",
            "Input: [ 1 -1  1]  |  Net: -8.00  |  Output: -1\n",
            "Input: [ 1  1 -1]  |  Net: -8.00  |  Output: -1\n",
            "Input: [1 1 1]  |  Net: 0.00  |  Output: -1\n"
          ]
        }
      ]
    }
  ]
}